# configs/eole/model_vit.yaml
model:
  architecture: transformer
  encoder:
    type: picto_encoder     #  custom encoder
    encoder_dim: 512
    
    img_size: 224
    patch_size: 16
    in_channels: 3
    visual_embed_dim: 192
    visual_heads: 3
    visual_mlp_ratio: 2.0
    visual_layers: 3
    visual_dim: 512
    
    #  encoder configuration
    category_vocab_size: 200
    type_vocab_size: 10
    semantic_embed_dim: 256
    semantic_dim: 512
    
    # fusion configuration
    fusion_hidden_dim: 512
  
  decoder:
    type: transformer
    hidden_size: 512
    layers: 6
    heads: 8
    transformer_ff: 2048
  
  embeddings:
    word_vec_size: 512
    position_encoding: true
    share_embeddings: true